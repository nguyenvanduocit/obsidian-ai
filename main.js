/*
THIS IS A GENERATED/BUNDLED FILE BY ESBUILD
if you want to view the source, please visit the github repository of this plugin
*/

var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// src/main.ts
var main_exports = {};
__export(main_exports, {
  default: () => AiCanvasPlugin
});
module.exports = __toCommonJS(main_exports);
var import_obsidian7 = require("obsidian");

// src/canvas/fns/getActiveCanvas.ts
var import_obsidian = require("obsidian");
var getActiveCanvas = (app) => {
  const canvasView = app.workspace.getActiveViewOfType(import_obsidian.ItemView);
  if ((canvasView == null ? void 0 : canvasView.getViewType()) === "canvas") {
    return canvasView.canvas;
  }
  return null;
};

// src/fns/createUserNode.ts
var import_obsidian2 = require("obsidian");

// src/util/constant.ts
var minWidth = 100;
var pxPerChar = 5;
var pxPerLine = 28;
var textPaddingHeight = 12;
var newNoteMargin = 60;
var minHeight = 60;

// src/canvas/fns/calcHeight.ts
var calcHeight = (options) => {
  const calcTextHeight = Math.round(
    textPaddingHeight + pxPerLine * options.text.length / (minWidth / pxPerChar)
  );
  return Math.max(options.parentHeight, calcTextHeight);
};

// src/canvas/fns/addEdge.ts
var addEdge = async (canvas, edgeID, fromEdge, toEdge) => {
  if (!canvas)
    return;
  const data = canvas.getData();
  if (!data)
    return;
  canvas.importData({
    edges: [
      ...data.edges,
      {
        id: edgeID,
        fromNode: fromEdge.node.id,
        fromSide: fromEdge.side,
        toNode: toEdge.node.id,
        toSide: toEdge.side
      }
    ],
    nodes: data.nodes
  });
  await canvas.requestFrame();
};

// src/canvas/fns/randomHexString.ts
var randomHexString = (len) => {
  const t = [];
  for (let n = 0; n < len; n++) {
    t.push((16 * Math.random() | 0).toString(16));
  }
  return t.join("");
};

// src/canvas/fns/createNode.ts
var createNode = async (canvas, parentNode, nodeOptions, nodeData) => {
  var _a, _b;
  const { text } = nodeOptions;
  const width = ((_a = nodeOptions == null ? void 0 : nodeOptions.size) == null ? void 0 : _a.width) || Math.max(minWidth, parentNode == null ? void 0 : parentNode.width);
  const height = ((_b = nodeOptions == null ? void 0 : nodeOptions.size) == null ? void 0 : _b.height) || Math.max(minHeight, parentNode && calcHeight({ text, parentHeight: parentNode.height }));
  const siblings = parent && canvas.getEdgesForNode(parentNode).filter((n) => n.from.node.id == parentNode.id).map((e) => e.to.node);
  const farLeft = parentNode.y - parentNode.width * 5;
  const siblingsRight = (siblings == null ? void 0 : siblings.length) ? siblings.reduce((right, sib) => Math.max(right, sib.x + sib.width), farLeft) : void 0;
  const priorSibling = siblings[siblings.length - 1];
  const x = siblingsRight != null ? siblingsRight + newNoteMargin : parentNode.x;
  const y = (priorSibling ? priorSibling.y : parentNode.y + parentNode.height + newNoteMargin) + // Using position=left, y value is treated as vertical center
  height * 0.5;
  const newNode = canvas.createTextNode({
    pos: { x, y },
    position: "left",
    size: { height, width },
    text,
    focus: false
  });
  if (nodeData) {
    newNode.setData(nodeData);
  }
  canvas.deselectAll();
  canvas.addNode(newNode);
  await addEdge(
    canvas,
    randomHexString(16),
    {
      side: "bottom",
      node: parentNode
    },
    {
      side: "top",
      node: newNode
    }
  );
  return newNode;
};

// src/fns/createUserNode.ts
var createUserNode = async (app) => {
  const canvas = getActiveCanvas(app);
  if (!canvas) {
    new import_obsidian2.Notice("No active canvas");
    return;
  }
  const currentSelection = canvas.selection;
  const selectedNode = currentSelection.values().next().value;
  canvas.deselectAll();
  const createdNode = await createNode(
    canvas,
    selectedNode,
    {
      text: ""
    },
    {
      chat_role: "user"
    }
  );
  canvas.selectOnly(
    createdNode,
    true
    /* startEditing */
  );
  await canvas.requestFrame();
  createdNode.startEditing();
};

// src/fns/generateModelMessage.ts
var import_obsidian4 = require("obsidian");

// node_modules/@google/generative-ai/dist/index.mjs
var HarmCategory;
(function(HarmCategory2) {
  HarmCategory2["HARM_CATEGORY_UNSPECIFIED"] = "HARM_CATEGORY_UNSPECIFIED";
  HarmCategory2["HARM_CATEGORY_HATE_SPEECH"] = "HARM_CATEGORY_HATE_SPEECH";
  HarmCategory2["HARM_CATEGORY_SEXUALLY_EXPLICIT"] = "HARM_CATEGORY_SEXUALLY_EXPLICIT";
  HarmCategory2["HARM_CATEGORY_HARASSMENT"] = "HARM_CATEGORY_HARASSMENT";
  HarmCategory2["HARM_CATEGORY_DANGEROUS_CONTENT"] = "HARM_CATEGORY_DANGEROUS_CONTENT";
})(HarmCategory || (HarmCategory = {}));
var HarmBlockThreshold;
(function(HarmBlockThreshold2) {
  HarmBlockThreshold2["HARM_BLOCK_THRESHOLD_UNSPECIFIED"] = "HARM_BLOCK_THRESHOLD_UNSPECIFIED";
  HarmBlockThreshold2["BLOCK_LOW_AND_ABOVE"] = "BLOCK_LOW_AND_ABOVE";
  HarmBlockThreshold2["BLOCK_MEDIUM_AND_ABOVE"] = "BLOCK_MEDIUM_AND_ABOVE";
  HarmBlockThreshold2["BLOCK_ONLY_HIGH"] = "BLOCK_ONLY_HIGH";
  HarmBlockThreshold2["BLOCK_NONE"] = "BLOCK_NONE";
})(HarmBlockThreshold || (HarmBlockThreshold = {}));
var HarmProbability;
(function(HarmProbability2) {
  HarmProbability2["HARM_PROBABILITY_UNSPECIFIED"] = "HARM_PROBABILITY_UNSPECIFIED";
  HarmProbability2["NEGLIGIBLE"] = "NEGLIGIBLE";
  HarmProbability2["LOW"] = "LOW";
  HarmProbability2["MEDIUM"] = "MEDIUM";
  HarmProbability2["HIGH"] = "HIGH";
})(HarmProbability || (HarmProbability = {}));
var BlockReason;
(function(BlockReason2) {
  BlockReason2["BLOCKED_REASON_UNSPECIFIED"] = "BLOCKED_REASON_UNSPECIFIED";
  BlockReason2["SAFETY"] = "SAFETY";
  BlockReason2["OTHER"] = "OTHER";
})(BlockReason || (BlockReason = {}));
var FinishReason;
(function(FinishReason2) {
  FinishReason2["FINISH_REASON_UNSPECIFIED"] = "FINISH_REASON_UNSPECIFIED";
  FinishReason2["STOP"] = "STOP";
  FinishReason2["MAX_TOKENS"] = "MAX_TOKENS";
  FinishReason2["SAFETY"] = "SAFETY";
  FinishReason2["RECITATION"] = "RECITATION";
  FinishReason2["OTHER"] = "OTHER";
})(FinishReason || (FinishReason = {}));
var TaskType;
(function(TaskType2) {
  TaskType2["TASK_TYPE_UNSPECIFIED"] = "TASK_TYPE_UNSPECIFIED";
  TaskType2["RETRIEVAL_QUERY"] = "RETRIEVAL_QUERY";
  TaskType2["RETRIEVAL_DOCUMENT"] = "RETRIEVAL_DOCUMENT";
  TaskType2["SEMANTIC_SIMILARITY"] = "SEMANTIC_SIMILARITY";
  TaskType2["CLASSIFICATION"] = "CLASSIFICATION";
  TaskType2["CLUSTERING"] = "CLUSTERING";
})(TaskType || (TaskType = {}));
var GoogleGenerativeAIError = class extends Error {
  constructor(message) {
    super(`[GoogleGenerativeAI Error]: ${message}`);
  }
};
var GoogleGenerativeAIResponseError = class extends GoogleGenerativeAIError {
  constructor(message, response) {
    super(message);
    this.response = response;
  }
};
var BASE_URL = "https://generativelanguage.googleapis.com";
var API_VERSION = "v1";
var PACKAGE_VERSION = "0.2.1";
var PACKAGE_LOG_HEADER = "genai-js";
var Task;
(function(Task2) {
  Task2["GENERATE_CONTENT"] = "generateContent";
  Task2["STREAM_GENERATE_CONTENT"] = "streamGenerateContent";
  Task2["COUNT_TOKENS"] = "countTokens";
  Task2["EMBED_CONTENT"] = "embedContent";
  Task2["BATCH_EMBED_CONTENTS"] = "batchEmbedContents";
})(Task || (Task = {}));
var RequestUrl = class {
  constructor(model, task, apiKey, stream) {
    this.model = model;
    this.task = task;
    this.apiKey = apiKey;
    this.stream = stream;
  }
  toString() {
    let url = `${BASE_URL}/${API_VERSION}/${this.model}:${this.task}`;
    if (this.stream) {
      url += "?alt=sse";
    }
    return url;
  }
};
function getClientHeaders() {
  return `${PACKAGE_LOG_HEADER}/${PACKAGE_VERSION}`;
}
async function makeRequest(url, body, requestOptions) {
  let response;
  try {
    response = await fetch(url.toString(), Object.assign(Object.assign({}, buildFetchOptions(requestOptions)), { method: "POST", headers: {
      "Content-Type": "application/json",
      "x-goog-api-client": getClientHeaders(),
      "x-goog-api-key": url.apiKey
    }, body }));
    if (!response.ok) {
      let message = "";
      try {
        const json = await response.json();
        message = json.error.message;
        if (json.error.details) {
          message += ` ${JSON.stringify(json.error.details)}`;
        }
      } catch (e) {
      }
      throw new Error(`[${response.status} ${response.statusText}] ${message}`);
    }
  } catch (e) {
    const err = new GoogleGenerativeAIError(`Error fetching from ${url.toString()}: ${e.message}`);
    err.stack = e.stack;
    throw err;
  }
  return response;
}
function buildFetchOptions(requestOptions) {
  const fetchOptions = {};
  if ((requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.timeout) >= 0) {
    const abortController = new AbortController();
    const signal = abortController.signal;
    setTimeout(() => abortController.abort(), requestOptions.timeout);
    fetchOptions.signal = signal;
  }
  return fetchOptions;
}
function addHelpers(response) {
  response.text = () => {
    if (response.candidates && response.candidates.length > 0) {
      if (response.candidates.length > 1) {
        console.warn(`This response had ${response.candidates.length} candidates. Returning text from the first candidate only. Access response.candidates directly to use the other candidates.`);
      }
      if (hadBadFinishReason(response.candidates[0])) {
        throw new GoogleGenerativeAIResponseError(`${formatBlockErrorMessage(response)}`, response);
      }
      return getText(response);
    } else if (response.promptFeedback) {
      throw new GoogleGenerativeAIResponseError(`Text not available. ${formatBlockErrorMessage(response)}`, response);
    }
    return "";
  };
  return response;
}
function getText(response) {
  var _a, _b, _c, _d;
  if ((_d = (_c = (_b = (_a = response.candidates) === null || _a === void 0 ? void 0 : _a[0].content) === null || _b === void 0 ? void 0 : _b.parts) === null || _c === void 0 ? void 0 : _c[0]) === null || _d === void 0 ? void 0 : _d.text) {
    return response.candidates[0].content.parts[0].text;
  } else {
    return "";
  }
}
var badFinishReasons = [FinishReason.RECITATION, FinishReason.SAFETY];
function hadBadFinishReason(candidate) {
  return !!candidate.finishReason && badFinishReasons.includes(candidate.finishReason);
}
function formatBlockErrorMessage(response) {
  var _a, _b, _c;
  let message = "";
  if ((!response.candidates || response.candidates.length === 0) && response.promptFeedback) {
    message += "Response was blocked";
    if ((_a = response.promptFeedback) === null || _a === void 0 ? void 0 : _a.blockReason) {
      message += ` due to ${response.promptFeedback.blockReason}`;
    }
    if ((_b = response.promptFeedback) === null || _b === void 0 ? void 0 : _b.blockReasonMessage) {
      message += `: ${response.promptFeedback.blockReasonMessage}`;
    }
  } else if ((_c = response.candidates) === null || _c === void 0 ? void 0 : _c[0]) {
    const firstCandidate = response.candidates[0];
    if (hadBadFinishReason(firstCandidate)) {
      message += `Candidate was blocked due to ${firstCandidate.finishReason}`;
      if (firstCandidate.finishMessage) {
        message += `: ${firstCandidate.finishMessage}`;
      }
    }
  }
  return message;
}
function __await(v) {
  return this instanceof __await ? (this.v = v, this) : new __await(v);
}
function __asyncGenerator(thisArg, _arguments, generator) {
  if (!Symbol.asyncIterator)
    throw new TypeError("Symbol.asyncIterator is not defined.");
  var g = generator.apply(thisArg, _arguments || []), i, q = [];
  return i = {}, verb("next"), verb("throw"), verb("return"), i[Symbol.asyncIterator] = function() {
    return this;
  }, i;
  function verb(n) {
    if (g[n])
      i[n] = function(v) {
        return new Promise(function(a, b) {
          q.push([n, v, a, b]) > 1 || resume(n, v);
        });
      };
  }
  function resume(n, v) {
    try {
      step(g[n](v));
    } catch (e) {
      settle(q[0][3], e);
    }
  }
  function step(r) {
    r.value instanceof __await ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r);
  }
  function fulfill(value) {
    resume("next", value);
  }
  function reject(value) {
    resume("throw", value);
  }
  function settle(f, v) {
    if (f(v), q.shift(), q.length)
      resume(q[0][0], q[0][1]);
  }
}
var responseLineRE = /^data\: (.*)(?:\n\n|\r\r|\r\n\r\n)/;
function processStream(response) {
  const inputStream = response.body.pipeThrough(new TextDecoderStream("utf8", { fatal: true }));
  const responseStream = getResponseStream(inputStream);
  const [stream1, stream2] = responseStream.tee();
  return {
    stream: generateResponseSequence(stream1),
    response: getResponsePromise(stream2)
  };
}
async function getResponsePromise(stream) {
  const allResponses = [];
  const reader = stream.getReader();
  while (true) {
    const { done, value } = await reader.read();
    if (done) {
      return addHelpers(aggregateResponses(allResponses));
    }
    allResponses.push(value);
  }
}
function generateResponseSequence(stream) {
  return __asyncGenerator(this, arguments, function* generateResponseSequence_1() {
    const reader = stream.getReader();
    while (true) {
      const { value, done } = yield __await(reader.read());
      if (done) {
        break;
      }
      yield yield __await(addHelpers(value));
    }
  });
}
function getResponseStream(inputStream) {
  const reader = inputStream.getReader();
  const stream = new ReadableStream({
    start(controller) {
      let currentText = "";
      return pump();
      function pump() {
        return reader.read().then(({ value, done }) => {
          if (done) {
            if (currentText.trim()) {
              controller.error(new GoogleGenerativeAIError("Failed to parse stream"));
              return;
            }
            controller.close();
            return;
          }
          currentText += value;
          let match = currentText.match(responseLineRE);
          let parsedResponse;
          while (match) {
            try {
              parsedResponse = JSON.parse(match[1]);
            } catch (e) {
              controller.error(new GoogleGenerativeAIError(`Error parsing JSON response: "${match[1]}"`));
              return;
            }
            controller.enqueue(parsedResponse);
            currentText = currentText.substring(match[0].length);
            match = currentText.match(responseLineRE);
          }
          return pump();
        });
      }
    }
  });
  return stream;
}
function aggregateResponses(responses) {
  const lastResponse = responses[responses.length - 1];
  const aggregatedResponse = {
    promptFeedback: lastResponse === null || lastResponse === void 0 ? void 0 : lastResponse.promptFeedback
  };
  for (const response of responses) {
    if (response.candidates) {
      for (const candidate of response.candidates) {
        const i = candidate.index;
        if (!aggregatedResponse.candidates) {
          aggregatedResponse.candidates = [];
        }
        if (!aggregatedResponse.candidates[i]) {
          aggregatedResponse.candidates[i] = {
            index: candidate.index
          };
        }
        aggregatedResponse.candidates[i].citationMetadata = candidate.citationMetadata;
        aggregatedResponse.candidates[i].finishReason = candidate.finishReason;
        aggregatedResponse.candidates[i].finishMessage = candidate.finishMessage;
        aggregatedResponse.candidates[i].safetyRatings = candidate.safetyRatings;
        if (candidate.content && candidate.content.parts) {
          if (!aggregatedResponse.candidates[i].content) {
            aggregatedResponse.candidates[i].content = {
              role: candidate.content.role || "user",
              parts: [{ text: "" }]
            };
          }
          for (const part of candidate.content.parts) {
            if (part.text) {
              aggregatedResponse.candidates[i].content.parts[0].text += part.text;
            }
          }
        }
      }
    }
  }
  return aggregatedResponse;
}
async function generateContentStream(apiKey, model, params, requestOptions) {
  const url = new RequestUrl(
    model,
    Task.STREAM_GENERATE_CONTENT,
    apiKey,
    /* stream */
    true
  );
  const response = await makeRequest(url, JSON.stringify(params), requestOptions);
  return processStream(response);
}
async function generateContent(apiKey, model, params, requestOptions) {
  const url = new RequestUrl(
    model,
    Task.GENERATE_CONTENT,
    apiKey,
    /* stream */
    false
  );
  const response = await makeRequest(url, JSON.stringify(params), requestOptions);
  const responseJson = await response.json();
  const enhancedResponse = addHelpers(responseJson);
  return {
    response: enhancedResponse
  };
}
function formatNewContent(request, role) {
  let newParts = [];
  if (typeof request === "string") {
    newParts = [{ text: request }];
  } else {
    for (const partOrString of request) {
      if (typeof partOrString === "string") {
        newParts.push({ text: partOrString });
      } else {
        newParts.push(partOrString);
      }
    }
  }
  return { role, parts: newParts };
}
function formatGenerateContentInput(params) {
  if (params.contents) {
    return params;
  } else {
    const content = formatNewContent(params, "user");
    return { contents: [content] };
  }
}
function formatEmbedContentInput(params) {
  if (typeof params === "string" || Array.isArray(params)) {
    const content = formatNewContent(params, "user");
    return { content };
  }
  return params;
}
var SILENT_ERROR = "SILENT_ERROR";
var ChatSession = class {
  constructor(apiKey, model, params, requestOptions) {
    this.model = model;
    this.params = params;
    this.requestOptions = requestOptions;
    this._history = [];
    this._sendPromise = Promise.resolve();
    this._apiKey = apiKey;
    if (params === null || params === void 0 ? void 0 : params.history) {
      this._history = params.history.map((content) => {
        if (!content.role) {
          throw new Error("Missing role for history item: " + JSON.stringify(content));
        }
        return formatNewContent(content.parts, content.role);
      });
    }
  }
  /**
   * Gets the chat history so far. Blocked prompts are not added to history.
   * Blocked candidates are not added to history, nor are the prompts that
   * generated them.
   */
  async getHistory() {
    await this._sendPromise;
    return this._history;
  }
  /**
   * Sends a chat message and receives a non-streaming
   * {@link GenerateContentResult}
   */
  async sendMessage(request) {
    var _a, _b;
    await this._sendPromise;
    const newContent = formatNewContent(request, "user");
    const generateContentRequest = {
      safetySettings: (_a = this.params) === null || _a === void 0 ? void 0 : _a.safetySettings,
      generationConfig: (_b = this.params) === null || _b === void 0 ? void 0 : _b.generationConfig,
      contents: [...this._history, newContent]
    };
    let finalResult;
    this._sendPromise = this._sendPromise.then(() => generateContent(this._apiKey, this.model, generateContentRequest, this.requestOptions)).then((result) => {
      var _a2;
      if (result.response.candidates && result.response.candidates.length > 0) {
        this._history.push(newContent);
        const responseContent = Object.assign({
          parts: [],
          // Response seems to come back without a role set.
          role: "model"
        }, (_a2 = result.response.candidates) === null || _a2 === void 0 ? void 0 : _a2[0].content);
        this._history.push(responseContent);
      } else {
        const blockErrorMessage = formatBlockErrorMessage(result.response);
        if (blockErrorMessage) {
          console.warn(`sendMessage() was unsuccessful. ${blockErrorMessage}. Inspect response object for details.`);
        }
      }
      finalResult = result;
    });
    await this._sendPromise;
    return finalResult;
  }
  /**
   * Sends a chat message and receives the response as a
   * {@link GenerateContentStreamResult} containing an iterable stream
   * and a response promise.
   */
  async sendMessageStream(request) {
    var _a, _b;
    await this._sendPromise;
    const newContent = formatNewContent(request, "user");
    const generateContentRequest = {
      safetySettings: (_a = this.params) === null || _a === void 0 ? void 0 : _a.safetySettings,
      generationConfig: (_b = this.params) === null || _b === void 0 ? void 0 : _b.generationConfig,
      contents: [...this._history, newContent]
    };
    const streamPromise = generateContentStream(this._apiKey, this.model, generateContentRequest, this.requestOptions);
    this._sendPromise = this._sendPromise.then(() => streamPromise).catch((_ignored) => {
      throw new Error(SILENT_ERROR);
    }).then((streamResult) => streamResult.response).then((response) => {
      if (response.candidates && response.candidates.length > 0) {
        this._history.push(newContent);
        const responseContent = Object.assign({}, response.candidates[0].content);
        if (!responseContent.role) {
          responseContent.role = "model";
        }
        this._history.push(responseContent);
      } else {
        const blockErrorMessage = formatBlockErrorMessage(response);
        if (blockErrorMessage) {
          console.warn(`sendMessageStream() was unsuccessful. ${blockErrorMessage}. Inspect response object for details.`);
        }
      }
    }).catch((e) => {
      if (e.message !== SILENT_ERROR) {
        console.error(e);
      }
    });
    return streamPromise;
  }
};
async function countTokens(apiKey, model, params, requestOptions) {
  const url = new RequestUrl(model, Task.COUNT_TOKENS, apiKey, false);
  const response = await makeRequest(url, JSON.stringify(Object.assign(Object.assign({}, params), { model })), requestOptions);
  return response.json();
}
async function embedContent(apiKey, model, params, requestOptions) {
  const url = new RequestUrl(model, Task.EMBED_CONTENT, apiKey, false);
  const response = await makeRequest(url, JSON.stringify(params), requestOptions);
  return response.json();
}
async function batchEmbedContents(apiKey, model, params, requestOptions) {
  const url = new RequestUrl(model, Task.BATCH_EMBED_CONTENTS, apiKey, false);
  const requestsWithModel = params.requests.map((request) => {
    return Object.assign(Object.assign({}, request), { model });
  });
  const response = await makeRequest(url, JSON.stringify({ requests: requestsWithModel }), requestOptions);
  return response.json();
}
var GenerativeModel = class {
  constructor(apiKey, modelParams, requestOptions) {
    this.apiKey = apiKey;
    if (modelParams.model.includes("/")) {
      this.model = modelParams.model;
    } else {
      this.model = `models/${modelParams.model}`;
    }
    this.generationConfig = modelParams.generationConfig || {};
    this.safetySettings = modelParams.safetySettings || [];
    this.requestOptions = requestOptions || {};
  }
  /**
   * Makes a single non-streaming call to the model
   * and returns an object containing a single {@link GenerateContentResponse}.
   */
  async generateContent(request) {
    const formattedParams = formatGenerateContentInput(request);
    return generateContent(this.apiKey, this.model, Object.assign({ generationConfig: this.generationConfig, safetySettings: this.safetySettings }, formattedParams), this.requestOptions);
  }
  /**
   * Makes a single streaming call to the model
   * and returns an object containing an iterable stream that iterates
   * over all chunks in the streaming response as well as
   * a promise that returns the final aggregated response.
   */
  async generateContentStream(request) {
    const formattedParams = formatGenerateContentInput(request);
    return generateContentStream(this.apiKey, this.model, Object.assign({ generationConfig: this.generationConfig, safetySettings: this.safetySettings }, formattedParams), this.requestOptions);
  }
  /**
   * Gets a new {@link ChatSession} instance which can be used for
   * multi-turn chats.
   */
  startChat(startChatParams) {
    return new ChatSession(this.apiKey, this.model, startChatParams, this.requestOptions);
  }
  /**
   * Counts the tokens in the provided request.
   */
  async countTokens(request) {
    const formattedParams = formatGenerateContentInput(request);
    return countTokens(this.apiKey, this.model, formattedParams);
  }
  /**
   * Embeds the provided content.
   */
  async embedContent(request) {
    const formattedParams = formatEmbedContentInput(request);
    return embedContent(this.apiKey, this.model, formattedParams);
  }
  /**
   * Embeds an array of {@link EmbedContentRequest}s.
   */
  async batchEmbedContents(batchEmbedContentRequest) {
    return batchEmbedContents(this.apiKey, this.model, batchEmbedContentRequest, this.requestOptions);
  }
};
var GoogleGenerativeAI = class {
  constructor(apiKey) {
    this.apiKey = apiKey;
  }
  /**
   * Gets a {@link GenerativeModel} instance for the provided model name.
   */
  getGenerativeModel(modelParams, requestOptions) {
    if (!modelParams.model) {
      throw new GoogleGenerativeAIError(`Must provide a model name. Example: genai.getGenerativeModel({ model: 'my-model-name' })`);
    }
    return new GenerativeModel(this.apiKey, modelParams, requestOptions);
  }
};

// src/fns/readNodeContent.ts
var import_obsidian3 = require("obsidian");
async function readFileContent(app, file, subpath) {
  var _a;
  const body = await app.vault.read(file);
  if (subpath) {
    const cache = app.metadataCache.getFileCache(file);
    if (cache) {
      const resolved = (0, import_obsidian3.resolveSubpath)(cache, subpath);
      if (!resolved) {
        console.warn("Failed to get subpath", { file, subpath });
        return body;
      }
      if (resolved.start || resolved.end) {
        const subText = body.slice(resolved.start.offset, (_a = resolved.end) == null ? void 0 : _a.offset);
        if (subText) {
          return subText;
        } else {
          console.warn("Failed to get subpath", { file, subpath });
          return body;
        }
      }
    }
  }
  return body;
}
async function readNodeContent(node) {
  const app = node.app;
  const nodeData = node.getData();
  switch (nodeData.type) {
    case "text":
      return nodeData.text;
    case "file":
      const file = app.vault.getAbstractFileByPath(nodeData.file);
      if (file instanceof import_obsidian3.TFile) {
        const body = await app.vault.read(file);
        if (node.subpath) {
          return await readFileContent(app, file, nodeData.subpath);
        } else {
          return `## ${file.basename}
${body}`;
        }
      } else {
        console.debug("Cannot read from file type", file);
      }
  }
}

// src/canvas/fns/walkNodes.ts
function nodeParents(node) {
  const canvas = node.canvas;
  const nodes = canvas.getEdgesForNode(node).filter((edge) => edge.to.node.id === node.id).map((edge) => edge.from.node);
  nodes.sort((a, b) => b.x - a.x);
  return nodes;
}
async function walkNode(start, walker, getNodeParents = nodeParents) {
  const visited = /* @__PURE__ */ new Set();
  const queue = [{ node: start, depth: 0 }];
  while (queue.length > 0) {
    const { node: currentNode, depth } = queue.shift();
    if (visited.has(currentNode.id)) {
      continue;
    }
    const shouldContinue = await walker(currentNode, depth);
    if (!shouldContinue) {
      break;
    }
    visited.add(currentNode.id);
    const parents = getNodeParents(currentNode);
    for (const parent2 of parents) {
      if (!visited.has(parent2.id)) {
        queue.push({ node: parent2, depth: depth + 1 });
      }
    }
  }
}

// src/fns/buildConversation.ts
var buildConversation = async (currentNode) => {
  const messages = [];
  const visit = async (node, depth) => {
    var _a;
    const nodeData = node.getData();
    let nodeText = ((_a = await readNodeContent(node)) == null ? void 0 : _a.trim()) || "";
    messages.push({
      parts: nodeText,
      role: nodeData.chatRole || "user"
    });
    return true;
  };
  await walkNode(currentNode, visit);
  return messages.reverse();
};

// src/fns/generateModelMessage.ts
var validateInput = (input) => {
  if (input.apiKey === "") {
    new import_obsidian4.Notice("API key is not set. Please set the API key in the settings");
    return false;
  }
  return true;
};
var prepareConversation = async (input, selectedNode, canvas) => {
  let conversation = await buildConversation(selectedNode);
  const createdNode = await createNode(
    canvas,
    selectedNode,
    {
      text: "Generating..."
    },
    {
      chatRole: "model",
      model: input.apiModel
    }
  );
  conversation.unshift({
    role: "user",
    parts: "you are a critical-thinking assistant bot. Consider the intent of my questions before responding. Do not restate my information unless I ask for it. Will not include caveats or disclaimers. Use step-by-step reasoning. Be brief."
  });
  return { conversation, createdNode };
};
var generateContent2 = async (input, conversation, createdNode, canvas) => {
  const genAI = new GoogleGenerativeAI(input.apiKey);
  const model = genAI.getGenerativeModel({ model: input.apiModel });
  const parts = [];
  let conversationIndex = 0;
  for (const message of conversation) {
    const content = message.parts;
    if (content.length == 0) {
      continue;
    }
    parts.push(`${content}`);
  }
  if (parts.length === 0) {
    new import_obsidian4.Notice("No content to generate");
    return;
  }
  try {
    const result = await model.generateContentStream(parts);
    let text = "";
    for await (const chunk of result.stream) {
      const chunkText = chunk.text();
      text += chunkText;
      await createdNode.setText(text);
    }
  } catch (error) {
    console.error(error);
    await createdNode.setText("Error: " + error.message);
  }
  await canvas.requestFrame();
};
var generateModelMessage = async (input, canvas, node) => {
  const isValidInput = validateInput(input);
  if (!isValidInput)
    return;
  const { conversation, createdNode } = await prepareConversation(input, node, canvas);
  await generateContent2(input, conversation, createdNode, canvas);
};

// node_modules/monkey-around/dist/index.mjs
function around(obj, factories) {
  const removers = Object.keys(factories).map((key) => around1(obj, key, factories[key]));
  return removers.length === 1 ? removers[0] : function() {
    removers.forEach((r) => r());
  };
}
function around1(obj, method, createWrapper) {
  const inherited = obj[method], hadOwn = obj.hasOwnProperty(method), original = hadOwn ? inherited : function() {
    return Object.getPrototypeOf(obj)[method].apply(this, arguments);
  };
  let current = createWrapper(original);
  if (inherited)
    Object.setPrototypeOf(current, inherited);
  Object.setPrototypeOf(wrapper, current);
  obj[method] = wrapper;
  return remove;
  function wrapper(...args) {
    if (current === original && obj[method] === wrapper)
      remove();
    return current.apply(this, args);
  }
  function remove() {
    if (obj[method] === wrapper) {
      if (hadOwn)
        obj[method] = original;
      else
        delete obj[method];
    }
    if (current === original)
      return;
    current = original;
    Object.setPrototypeOf(wrapper, inherited || Function);
  }
}

// src/fns/patchNodeMenu.ts
var patchNodeMenu = (plugin) => {
  var _a;
  const menu = (_a = getActiveCanvas(plugin.app)) == null ? void 0 : _a.menu;
  if (!menu) {
    return false;
  }
  const menuUninstaller = around(menu.constructor.prototype, {
    render: (next) => {
      return function(...args) {
        const result = next.call(this, ...args);
        if (this.menuEl.children.length === 0)
          return result;
        if (this.canvas.selection.size !== 1)
          return result;
        const selectedObject = this.canvas.selection.values().next().value;
        if (Object.prototype.hasOwnProperty.call(selectedObject, "path"))
          return result;
        if (Object.prototype.hasOwnProperty.call(selectedObject, "bgPath"))
          return result;
        plugin.events.trigger("canvas:node-menu", this, this.canvas, selectedObject);
        return result;
      };
    }
  });
  plugin.register(menuUninstaller);
  return true;
};

// src/settings/default.ts
var DEFAULT_SYSTEM_PROMPT = `
You are a critical-thinking assistant bot.
Consider the intent of my questions before responding.
Do not restate my information unless I ask for it.
Do not include caveats or disclaimers.
Use step-by-step reasoning. Be brief.`.trim();
var DEFAULT_SETTINGS = {
  apiKey: "",
  apiModel: "gpt-4-1106-preview",
  temperature: 1,
  systemPrompt: DEFAULT_SYSTEM_PROMPT,
  debug: false,
  maxInputTokens: 0,
  maxResponseTokens: 0,
  maxDepth: 0,
  systemPrompts: [],
  userSystemPrompts: []
};

// src/settings/SettingsTab.ts
var import_obsidian5 = require("obsidian");
var SettingsTab = class extends import_obsidian5.PluginSettingTab {
  constructor(app, plugin) {
    super(app, plugin);
    this.plugin = plugin;
  }
  display() {
    const { containerEl } = this;
    containerEl.empty();
    new import_obsidian5.Setting(containerEl).setName("Model").setDesc("Select the GPT model to use.").addText((cb) => {
      cb.setValue(this.plugin.settings.apiModel);
      cb.onChange(async (value) => {
        this.plugin.settings.apiModel = value;
        await this.plugin.saveSettings();
      });
    });
    new import_obsidian5.Setting(containerEl).setName("API key").setDesc(
      "The API key to use when making requests - Get from OpenAI"
    ).addText((text) => {
      text.inputEl.type = "password";
      text.setPlaceholder("API Key").setValue(this.plugin.settings.apiKey).onChange(async (value) => {
        this.plugin.settings.apiKey = value;
        await this.plugin.saveSettings();
      });
    });
    new import_obsidian5.Setting(containerEl).setName("Default system prompt").setDesc(
      `The system prompt sent with each request to the API. 
(Note: you can override this by beginning a note stream with a note starting 'SYSTEM PROMPT'. The remaining content of that note will be used as system prompt.)`
    ).addTextArea((component) => {
      component.inputEl.rows = 6;
      component.inputEl.addClass("augmented-canvas-settings-prompt");
      component.setValue(this.plugin.settings.systemPrompt);
      component.onChange(async (value) => {
        this.plugin.settings.systemPrompt = value;
        await this.plugin.saveSettings();
      });
    });
    new import_obsidian5.Setting(containerEl).setName("Max input tokens").setDesc(
      "The maximum number of tokens to send (within model limit). 0 means as many as possible"
    ).addText(
      (text) => text.setValue(this.plugin.settings.maxInputTokens.toString()).onChange(async (value) => {
        const parsed = parseInt(value);
        if (!isNaN(parsed)) {
          this.plugin.settings.maxInputTokens = parsed;
          await this.plugin.saveSettings();
        }
      })
    );
    new import_obsidian5.Setting(containerEl).setName("Max response tokens").setDesc(
      "The maximum number of tokens to return from the API. 0 means no limit. (A token is about 4 characters)."
    ).addText(
      (text) => text.setValue(this.plugin.settings.maxResponseTokens.toString()).onChange(async (value) => {
        const parsed = parseInt(value);
        if (!isNaN(parsed)) {
          this.plugin.settings.maxResponseTokens = parsed;
          await this.plugin.saveSettings();
        }
      })
    );
    new import_obsidian5.Setting(containerEl).setName("Max depth").setDesc(
      "The maximum depth of ancestor notes to include. 0 means no limit."
    ).addText(
      (text) => text.setValue(this.plugin.settings.maxDepth.toString()).onChange(async (value) => {
        const parsed = parseInt(value);
        if (!isNaN(parsed)) {
          this.plugin.settings.maxDepth = parsed;
          await this.plugin.saveSettings();
        }
      })
    );
    new import_obsidian5.Setting(containerEl).setName("Temperature").setDesc("Sampling temperature (0-2). 0 means no randomness.").addText(
      (text) => text.setValue(this.plugin.settings.temperature.toString()).onChange(async (value) => {
        const parsed = parseFloat(value);
        if (!isNaN(parsed) && parsed >= 0 && parsed <= 2) {
          this.plugin.settings.temperature = parsed;
          await this.plugin.saveSettings();
        }
      })
    );
  }
};
var SettingsTab_default = SettingsTab;

// src/Event.ts
var import_obsidian6 = require("obsidian");
var CanvasEvents = class extends import_obsidian6.Events {
  constructor() {
    super();
  }
  on(event, callback) {
    return super.on(event, callback);
  }
  trigger(name, ...args) {
    return super.trigger(name, ...args);
  }
};

// src/main.ts
var AiCanvasPlugin = class extends import_obsidian7.Plugin {
  constructor(app, pluginManifest, pluginPath) {
    super(app, pluginManifest);
    this.events = new CanvasEvents();
  }
  async onload() {
    await this.loadSettings();
    this.addSettingTab(new SettingsTab_default(this.app, this));
    this.registerCommands();
    this.patchObsidian();
    this.registerEvents();
  }
  registerEvents() {
    this.registerEvent(
      this.events.on("canvas:node-menu", (menu, canvas, node) => {
        if (menu.menuEl.querySelector(".gpt-menu-item"))
          return;
        console.log("canvas:node-menu");
        const buttonEl_AskQuestion = createEl("button", "clickable-icon gpt-menu-item");
        (0, import_obsidian7.setTooltip)(buttonEl_AskQuestion, "Ask question with AI", {
          placement: "top"
        });
        (0, import_obsidian7.setIcon)(buttonEl_AskQuestion, "lucide-sparkles");
        buttonEl_AskQuestion.addEventListener("click", async () => {
          this.events.trigger("canvas:node-menu:ask-question", canvas, node);
        });
        menu.menuEl.appendChild(buttonEl_AskQuestion);
      })
    );
    this.registerEvent(
      this.events.on("canvas:node-menu:ask-question", async (canvas, node) => {
        if (!this.settings.apiKey || !this.settings.apiModel) {
          new import_obsidian7.Notice("API key or model is not set. Please set the API key and model in the settings");
          return;
        }
        await generateModelMessage(
          {
            apiKey: this.settings.apiKey,
            apiModel: this.settings.apiModel
          },
          canvas,
          node
        );
      })
    );
  }
  patchObsidian() {
    patchNodeMenu(this) || this.app.workspace.onLayoutReady(() => {
      if (patchNodeMenu(this))
        return;
      const evt = this.app.workspace.on("layout-change", () => {
        patchNodeMenu(this) && this.app.workspace.offref(evt);
      });
      this.registerEvent(evt);
    });
  }
  async loadSettings() {
    this.settings = Object.assign({}, DEFAULT_SETTINGS, await this.loadData());
  }
  async saveSettings() {
    await this.saveData(this.settings);
  }
  registerCommands() {
    const commands = [
      {
        id: "create-user-node",
        name: "Create User Node",
        callback: async () => {
          await createUserNode(this.app);
        }
      }
    ];
    commands.forEach((command) => this.addCommand(command));
  }
};
/*! Bundled license information:

@google/generative-ai/dist/index.mjs:
  (**
   * @license
   * Copyright 2023 Google LLC
   *
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *   http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *)

@google/generative-ai/dist/index.mjs:
  (**
   * @license
   * Copyright 2023 Google LLC
   *
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *   http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *)
*/
